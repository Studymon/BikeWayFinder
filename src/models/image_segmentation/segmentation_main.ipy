import os
from os import path

import torch
from torch.utils.data import DataLoader
from torch.utils.data.distributed import DistributedSampler

from segmentation_setup.segmentation_setup import * 
# segmentation_setup is a custom module containing  necessary functions and classes for image segmentation
# Note: this requires pip install of `inplace_abn`, which requires further setup steps if using without CUDA

place_name = "Stuttgart"

##########################################
#### Segment images and return predictions
##########################################

# Set device, NOTE: Not recommended to use CPU
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

# Set WD to the root directory
os.chdir('../../..')

# Set configuration
snapshot = "wide_resnet38_deeplab_vistas.pth.tar"
os.chdir(f'data_visible/interim/svi/{place_name}')  # go to the directory for image segmentation
data = "sorted_images/class_kept/sampled_edges"  # input directory, imagaes to segment
output = "sampled_edges_img_output"  # output directory, segmented images
pred_output = "sampled_edges_pred_output"  # output directory, tensor containing class prediction per pixel
prob_output = "sampled_edges_prob_output"  # output directory, tensor containing class probabilities per pixel
scales = "[1, 2, 2.7, 3.5]"  # scales used for multi-scale inference
do_flip = False  # whether to use horizontal flip for inference (False for now, as it doubles the inference time without significant improvement in accuracy)
output_mode = "palette"
fusion_mode = "mean"  # fusion mode for multi-scale inference
world_size = 1
rank = 0

# Create model by loading a snapshot
body, head, cls_state = load_snapshot(snapshot)
model = SegmentationModule(body, head, 256, 65, fusion_mode)
model.cls.load_state_dict(cls_state)
model = model.to(device).eval()
print(model)

# Create data loader
transformation = SegmentationTransform(
    640,  # size of the largest pixel dimension
    (0.41738699, 0.45732192, 0.46886091),
    (0.25685097, 0.26509955, 0.29067996),
)
dataset = SegmentationDataset(data, transformation)
data_loader = DataLoader(
    dataset,
    batch_size=1,
    pin_memory=True,
    sampler=DistributedSampler(dataset, world_size, rank),
#    num_workers=2,
    collate_fn=segmentation_collate,
    shuffle=False,
)


###########################
#### Run image segmentation
###########################

scales = eval(scales)

with torch.no_grad():
    for batch_i, rec in enumerate(data_loader):
        print("Testing batch [{:3d}/{:3d}]".format(batch_i + 1, len(data_loader)))

        img = rec["img"].to(device)
        probs, preds = model(img, scales, do_flip)

        for i, (prob, pred) in enumerate(
            zip(torch.unbind(probs, dim=0), torch.unbind(preds, dim=0))
        ):
            out_size = rec["meta"][i]["size"]
            img_name = rec["meta"][i]["idx"]

            # Save prediction image
            prob = prob.cpu()
            pred = pred.cpu()
            pred_img = get_pred_image(pred, out_size, output_mode == "palette")
            pred_img.save(path.join(output, img_name + ".png"))

            # Save prediction tensor
            pred = pred.to(torch.uint8)
            tensor_filename = path.join(pred_output, img_name + "_pred.pt")
            save_compressed_tensor(pred, tensor_filename)
            
            # Save probability tensor
            #prob = prob.to(torch.float16)
            #tensor_filename = path.join(prob_output, img_name + "_prob.pt")
            #save_compressed_tensor(prob, tensor_filename)
            